\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage[spanish]{babel}
\usepackage{gnuplottex}
\usepackage{fancyhdr}
\usepackage{minted}
\usepackage{multicol}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\tikzset{>=stealth}
\tikzset{vertex/.style = {shape=circle,draw,minimum size=2em}}
\tikzset{edge/.style = {-Latex}}

\title{Implementación en Haskell del algoritmo Bellman-Ford}
\author{David Davó Laviña}
\date{\today{}}

\pagestyle{fancy}
\fancyhf{}
\makeatletter
\fancyhead[RO]{\@author}
\fancyhead[LO]{\@title}
\makeatother

\setminted{
	frame=lines,
	baselinestretch=1.2,
}
\usemintedstyle {emacs}

\begin{document}
\section{Entrada y salida}
Tanto la entrada como la salida están representadas como ternas donde el primer elemento es el vértice origen, el segundo el vértice destino y el tercero el peso.

La interfaz por linea de comandos recibe la ruta de un archivo de entrada, y la ruta de otro de salida. En caso de recibir la ruta `\texttt{-}', se usará \texttt{stdin} y/o \texttt{stdout}.

\begin{verbatim}
Usage: ./bellmanford [-f] [-p] [-s n] [-d] input output
    -s n            uses n as source for the algorithm. By default n=0
    -p              uses patricia trees instead of arrays as backend
    -f              indicates that number should be treated as floats
    -d              indicates the delimiter to be used. Space by default

    Files are a weighted edgelist as generated by Python Networkx
      starting from 0
\end{verbatim}

\section{Ventajas y desventajas de usar Haskell}
La primera y más importante de todas es que así he aprendido a usar Haskell a un nivel ligeramente más avanzado que en Programación Declarativa, con un uso intensivo de operaciones monádicas, y operaciones de entrada-salida.

Haskell, al ser un lenguaje de evaluación perezosa, puede disminuir el tiempo de computación enormemente, al evitar la evaluación de distintos términos, o al permitir fácilmente el uso de multithreading cambiando las opciones de compilación.

Su entrada y salida es también perezosa, por lo que de incluirlo en un pipe entre dos procesos, se gestionará automáticamente, evaluando los resultados conforme vayan estando disponibles. Como no es necesario generar toda la entrada para poder generar toda la salida (a no ser que así lo requiera el problema), favorece la segmentación.

El problema es, que si queremos analizar el coste temporal del algoritmo, sin usar un profiler es tarea difícil, pues incluso la entrada/salida es perezosa. Aún así, la entrada se ha hecho recibiendo una lista de aristas, con lo que tenemos un coste de $\mathbb{O}\left(E\right)$. La salida retorna el predecesor y coste de cada vértice, por lo que tendrá un coste del orden de $\mathbb{O}\left(V\right)$.

Siendo el coste del algoritmo $\mathbb{O}\left(E\cdot V\right)$, tendríamos que el coste total de la operación lectura-evaluación-escritura sería $\mathbb{O}\left(E + E\cdot V + V\right)=\mathbb{O}\left(E\cdot V\right)$, por lo que podríamos observar en las gráficas que la complejidad asintótica del algoritmo permanece igual.

\section{Monticulos sesgados en C++}
Para el montículo se ha definido una clase parametrizada \mintinline{C++}|SkewHeap<K,V>|, donde \texttt{K} es el tipo de la clave y \texttt{V} el del valor a asignar. Tanto en los tests como en el análisis estadístico se ha usado la clase con claves de tipo \mintinline{C++}|unsigned|. Dicha clase guarda tan solo una variable de tipo \textit{Node}, que es la raíz del montículo. La clase \textit{Nodo} guarda la clave, el valor, y 3 punteros: a su padre, su hijo izquierdo, y su hijo derecho.

Las dos funciones más relevantes, \textit{join} y \textit{decreaseKey}, se han implementado tal que así:

\begin{minted}[linenos]{C++}
Node * join(Node * n1, Node * n2) {
  if (n1 == nullptr) return n2;
  if (n2 == nullptr) return n1;

  if (n1->_key > n2->_key)
	std::swap(n1, n2);

  std::swap(n1->_left, n1->_right);
  n1->_left = join(n1->_left, n2);
  n1->_left->_up = n1;

  return n1;
}
\end{minted}
\begin{minted}[linenos]{C++}
void decreaseKey(Node * node, K newKey) {
  if (_root == nullptr) throw EmptyHeapException();
  if (node == nullptr) throw std::invalid_argument("Can't decrease nullptr");
  if (newKey > node->_key) throw KeyGreaterException();

  auto & up = node->_up;
  node->_key = newKey;

  if (up != nullptr) {
	if (node != up->_right)
	  std::swap(up->_left, up->_right);

	up->_right = nullptr;
	node->_up = nullptr;

	_root = join(_root, node);
	_root->_up = nullptr;
}
\end{minted}

\section{Representación de los grafos en C++}
El grafo se ha representado como una lista de adyaciencia parametrizada
en el tipo de los pesos de las aristas, implementada como un vector estándar del 
tipo \texttt{Vertex<W>}. El tipo Vertex se ha implementado como un struct que
contiene una \texttt{string} etiqueta (no usada en el algoritmo), un descriptor de
vertice (\texttt{vertex\_descriptor}) que le identifica en el grafo (su posición en
la lista de adyacencia), y un vector estándar de aristas (\texttt{Edge<W>}). Cada arista es un struct compuesto por el descriptor de arista (\texttt{edge\_descriptor}), el peso de tipo \texttt{W}, y los descriptores de vértice tanto del vertice al que va, como del que viene. El descriptor de vértice del vértice que viene junto al descriptor de arista nos permiten identificar una arista en el grafo. El vértice con descriptor de vértice 0 se considerará el vértice nulo, cualquier intento de usar la función para añadir una arista al vértice nulo resultará en excepción.
\begin{minted}{C++}
typedef unsigned edge_descriptor;
typedef unsigned vertex_descriptor;

template <class W> 
struct Edge {
    edge_descriptor ed;
    vertex_descriptor to;
    vertex_descriptor from;
    W weight;
};

template <class W>
struct Vertex {
    vertex_descriptor vd;
    std::string label;
    std::vector<Edge<W>> edges;
};

template <class W> using Graph = std::vector<Vertex<W>>;
\end{minted}

\section{Algoritmo de Dijkstra en C++}
Nuestra función recibe un grafo y un vértice "fuente" desde el que calcularemos los caminos mínimos. Retorna un vector de pares donde, para cada uno de los vértices, retorna la suma de los pesos por ese camino, y el antecesor a ese nodo, produciendo el árbol de caminos mínimos. Para los vértices no conectados el peso del camino será el máximo que permita el tipo, y el predecesor será el vértice nulo (vértice con descriptor 0).

Por conveniencia declaramos dos vectores distintos, el vector de caminos y el vector de distancias. También declaramos la cola de prioridad implementada con el montículo sesgado y una lista de referencias a los nodos, para poder asociar cada vértice con su entrada en la lista de prioridad y poder decrecer la clave.

Primero poblamos las tablas de distancias (con 0 si es el vértice fuente y $\infty$\footnote{\mintinline{C++}|std::numeric_limits<W>::max()|} en caso contrario) y camino (con el vértice nulo como predecesor). Además, insertamos los nodos en la cola de prioridad y guardamos sus referencias en la tabla para poder decrecer el valor de la clave en el montículo. Hay que tener cuidado con el tipo de los pesos, pues no hay ningún tipo de detección de desbordamiento.

A continuación, realizamos el algoritmo de Dijkstra: mientras que la cola no esté vacía, sacamos el nodo más cercano y comprobamos todos sus vecinos (no comprobados anteriormente), actualizando la lista de distancias, caminos y la cola de prioridad si encontramos un camino más corto que el que teníamos anteriormente. Como durante el bucle se cumple el invariante $Q = V - S$ \cite{CormenDijsktra}, siendo $Q$ la cola de prioridad, $V$ la lista de vértices y $S$ los nodos ya visitados, podemos ver los nodos que hemos visitado usando solo la lista de referencias a la cola de prioridad, si tras visitar un nodo modificamos su entrada en la lista de referencias a nullptr.

Finalmente, retornamos el \textit{zip} de ambos vectores.

\begin{minted}{C++}
template <class W>
std::vector<std::pair<W, vertex_descriptor>> dijkstra(
	const Graph<W> & g, vertex_descriptor vd) {
  if (vd == 0) throw std::range_error("vertex can't be 0 (NULL)");
  std::vector<W> distances(g.size());
  std::vector<vertex_descriptor> path(g.size());

  SkewHeap<W, vertex_descriptor> pq;
  using SHNode = typename SkewHeap<W, vertex_descriptor>::Node;
  std::vector<SHNode *> nodes(g.size());

  for (vertex_descriptor i = 1; i < g.size(); ++i) {
    distances[i] = (i==vd)?0:std::numeric_limits<W>::max();
    path[i] = 0;
    nodes[i] = pq.insert(distances[i], i);
  }

  while(!pq.empty()) {
    vertex_descriptor currentV = pq.getMin()->getVal();
    nodes[pq.getMin()->getVal()] = nullptr;
    pq.deleteMin();

    for (Edge<W> e : g[currentV].edges) {
      if (nodes[e.to] == nullptr) continue;
      W tmpdst = distances[currentV] + e.weight;
      if (tmpdst < distances[e.to]) {
        distances[e.to] = tmpdst;
        path[e.to] = currentV;
        pq.decreaseKey(nodes[e.to], tmpdst);
      }
    }
  }

  /**
  ...
  return zip(distances, path)
  **/
}
\end{minted}

\section{Tests Unitarios en C++}
Para comprobar que se han implementado correctamente las estructuras de datos y los algoritmos, se han realizado distintos tests unitarios con Googletest\footnote{\url{https://github.com/google/googletest}}.

Como casos de prueba automatizados para el algoritmo de Dijsktra se han usado los dos siguientes grafos:

\vspace*{1em}
\noindent\begin{minipage}{.45\textwidth}
\centering
\begin{tikzpicture}
\node[vertex] (v1) at (0,0) {1};
\node[vertex] (v2) at (2,0) {2};

\draw[edge] (v1) to node[above] {100} (v2);
\end{tikzpicture}
\end{minipage} %
\begin{minipage}{.45\textwidth}
\centering
\begin{tikzpicture}
\node[vertex] (v1) at (0,0) {1};
\node[vertex] (v2) at (2,1) {2};
\node[vertex] (v3) at (2,-1) {3};

\draw[edge] (v1) to node[above] {500} (v2);
\draw[edge] (v1) to node[below] {100} (v3);
\draw[edge] (v3) to node[right] {50} (v2);
\end{tikzpicture}
\end{minipage}

El primero es trivial, y el segundo debería devolver el camino 1, 3, 2 con peso 150 para el nodo 2; y el camino 1,3 para el nodo 3; el nodo 1 debería tener como predecesor el vértice nulo y coste 0. También se han realizado pruebas con grafos más grandes ``a mano", como con el laberinto de Sedgewick \cite{SedgewickLabyrinth} y pequeños grafos generados aleatoriamente.

El código de dichos tests unitarios puede encontrarse en la carpeta \texttt{test/}

\section{Generación de las gráficas}
Para el tratamiento estadístico de datos se han generado grafos aleatorios con el modelo Erdős-Rényi, usando la función \texttt{gnp\_random\_graph} de la librería networkx\footnote{\url{https://networkx.github.io/}} de Python. Los grafos generados se pasarían mediante un pipe al programa \texttt{bellman-ford}, que leería el grafo de la entrada estándar y retornaría el predecesor y el coste total de los caminos a cada uno de los nodos, guardado en un archivo csv, junto con el tiempo que ha tardado en ejecutar el programa. Dicha salida será interpretada por Python, que generará un csv con el número de vértices y el tiempo, que será representado por gnuplot. Se han generado diversos archivos con distinta densidad de vértices ($0.01$, $0.05$, $0.1$, $0.25$, $0.5$ y $1$). En lugar de guardar los archivos con los grafos generados (de hasta varios GB para grafos densos), se han generado los grafos de prueba con la misma semilla: 42, por lo que los grafos se pueden volver a generar fácilmente usando la misma semilla y la misma función.

Para minimizar el efecto del resto del programa (I/O) se han generado los archivos en la memoria RAM, montando un sistema de ficheros temporal con \texttt{tmpfs}.

Se ha ejecutado en un ordenador con una instalación `fresca' de Arch Linux, en CLI, y sin conexión a internet.

\newpage
\section{Análisis de tiempo}
El insertar cada uno de los vértices a la cola de prioridad tendrá un coste de $\mathcal{O}(n\log n)$. A la hora de realizar el bucle mientras que no esté vacío, recorreremos todos los vértices eliminando la clave ($\mathcal{O} (\log n)$) y, para cada uno de sus vecinos, podemos decrecer la clave $\mathcal{O}(\log n)$. Esto nos deja un coste de $\mathcal{O}\left(a\log n+n\log n\right)$, donde $a$ es el número de aristas y $n$ el número de vértices. Podemos implementar el algoritmo en un tiempo menor con una cola de prioridad en la que \textit{decrecerClave} tenga coste constante, en cuyo caso el coste será $\mathcal{O}(a + n\log n)$. En nuestro caso, al generar grafos aleatorios con una densidad de aristas dada, el número de aristas será $a = \alpha\cdot(n\cdot(n-1))/2$, por lo que el coste en complejidad será del orden $\mathcal{O}((\alpha\cdot n^2+n)\log n)$. Cuando el grafo sea muy disperso ($\alpha$ pequeño), $\alpha\cdot n^2$ será menor que $n$. En la figura \ref{fig:graphTimeDijkstra} vemos el tiempo de ejecución en algoritmos aleatorios con distinto número de aristas (dependiente del número de vértices). Como podemos observar en la gráfica, se ajustan mucho a la función $(an^2+bn)\cdot log(n)$. Es más, la media de las desviaciones medias de las cuatro funciones es $\sigma=0.05486$

% \nocite{*} % <-- Recuerda quitar esto
\bibliographystyle{alpha}
\bibliography{references}

\end{document}